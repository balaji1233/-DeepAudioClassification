{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.**Import** **and Install Dependencies** **bold text**"
      ],
      "metadata": {
        "id": "7Uzip3_WAAav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Dependencies"
      ],
      "metadata": {
        "id": "SE32QNhGChMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-io matplotlib"
      ],
      "metadata": {
        "id": "o6ZojJyeAKV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load Dependencies"
      ],
      "metadata": {
        "id": "Ql6EzZWYCkWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf \n",
        "import tensorflow_io as tfio"
      ],
      "metadata": {
        "id": "r-Oi81TbCnFQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Load Dataset & Build Data Loading Function**"
      ],
      "metadata": {
        "id": "yD7lpSP0CrZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Paths to Files"
      ],
      "metadata": {
        "id": "GrmKzvbyHchI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CAPUCHIN_FILE = os.path.join('data', 'Parsed_Capuchinbird_Clips', 'XC3776-3.wav')\n",
        "NOT_CAPUCHIN_FILE = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhzAz6BdCwkR",
        "outputId": "67192ca2-591f-4967-d700-301422e3ec54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Build Dataloading Function"
      ],
      "metadata": {
        "id": "Q9dtpwo_Hn_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "    # Load encoded wav file\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    # Decode wav (tensors by channels) \n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "    # Removes trailing axis\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ],
      "metadata": {
        "id": "zAHAdGd-GGZZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Wave"
      ],
      "metadata": {
        "id": "wGL69i52HufD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wave = load_wav_16k_mono(CAPUCHIN_FILE)\n",
        "nwave = load_wav_16k_mono(NOT_CAPUCHIN_FILE)"
      ],
      "metadata": {
        "id": "Z9Ca08GRHuLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wave)\n",
        "plt.plot(nwave)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kBFXuvdZGWPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Tensorflow** **Dataset**"
      ],
      "metadata": {
        "id": "3liRdsxjH4DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Paths to Positive and Negative Data"
      ],
      "metadata": {
        "id": "sl3cTNRgH8gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POS = os.path.join('data', 'Parsed_Capuchinbird_Clips')\n",
        "NEG = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips')"
      ],
      "metadata": {
        "id": "xKAQk54iGb0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add labels and Combine Positive and Negative Samples"
      ],
      "metadata": {
        "id": "aq5AIxrbIGHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
        "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
        "data = positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "1B4MR1I4IJp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Determine Average Length of a Capuchin Call**"
      ],
      "metadata": {
        "id": "R7NIuWsMIV-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Calculate Wave Cycle Length"
      ],
      "metadata": {
        "id": "ZFoNsyhlIX9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = []\n",
        "for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n",
        "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file))\n",
        "    lengths.append(len(tensor_wave))"
      ],
      "metadata": {
        "id": "Zr36ELGgIXGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Calculate Mean, Min and Max"
      ],
      "metadata": {
        "id": "TQpP1f6wIh3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_mean(lengths)"
      ],
      "metadata": {
        "id": "t0je2bdDIqIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_min(lengths)"
      ],
      "metadata": {
        "id": "MptZjWV8ItLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.math.reduce_max(lengths)"
      ],
      "metadata": {
        "id": "YMzFVBFZIuM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Preprocessing Function to Convert to Spectrogram**"
      ],
      "metadata": {
        "id": "5X1md2NAJlc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Build Preprocessing Function"
      ],
      "metadata": {
        "id": "HnuqwyI-JqMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path, label): \n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:48000]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, wav],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, label"
      ],
      "metadata": {
        "id": "LhQaeRLnJwhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Out the Function and Viz the Spectrogram"
      ],
      "metadata": {
        "id": "aKAztj9RJzN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "k331o8ILJzAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrogram, label = preprocess(filepath, label)"
      ],
      "metadata": {
        "id": "zxNlB2zDJ3C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(tf.transpose(spectrogram)[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LcPkA8KlJ4wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Training and Testing Partitions**"
      ],
      "metadata": {
        "id": "kl00YU5RJ7W_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Tensorflow Data Pipeline"
      ],
      "metadata": {
        "id": "uwX1imbMJ9mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(preprocess)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1000)\n",
        "data = data.batch(16)\n",
        "data = data.prefetch(8)"
      ],
      "metadata": {
        "id": "THU_FnOuKANk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into Training and Testing Partitions"
      ],
      "metadata": {
        "id": "de-ieuqYKEh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.take(36)\n",
        "test = data.skip(36).take(15)"
      ],
      "metadata": {
        "id": "_4pQiuLhKD5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Test One Batch"
      ],
      "metadata": {
        "id": "nqVgBQtNKKzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples, labels = train.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "jvz0BgCHKMoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples.shape"
      ],
      "metadata": {
        "id": "YAoxgG6DKOkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Deep Learning Mode**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ifFitAPLKRBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load Tensorflow Dependencies"
      ],
      "metadata": {
        "id": "_1ora_w2KbJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
      ],
      "metadata": {
        "id": "21G0djaVKOZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Sequential Model, Compile and View Summary"
      ],
      "metadata": {
        "id": "rtwNVQHYKe-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
        "model.add(Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "OH3PxlVCLQYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.m"
      ],
      "metadata": {
        "id": "DQG6yxRlLVIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "zhWwn3sELamh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit Model, View Loss and KPI Plots"
      ],
      "metadata": {
        "id": "1kYPOm0GLepl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train, epochs=4, validation_data=test)"
      ],
      "metadata": {
        "id": "IXirbSLLLdlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(hist.history['loss'], 'r')\n",
        "plt.plot(hist.history['val_loss'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RVEScP04LhH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Precision')\n",
        "plt.plot(hist.history['precision'], 'r')\n",
        "plt.plot(hist.history['val_precision'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rt_8GxaJLhE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Recall')\n",
        "plt.plot(hist.history['recall'], 'r')\n",
        "plt.plot(hist.history['val_recall'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mDYJkKBQLnSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Make a Prediction on a Single Clip**"
      ],
      "metadata": {
        "id": "q_ZPflPgLrMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get One Batch and Make a Prediction"
      ],
      "metadata": {
        "id": "f1Sm3M0GLtnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "n63nAaswLqr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(X_test)"
      ],
      "metadata": {
        "id": "VIkv2GdILzyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Logits to Classes"
      ],
      "metadata": {
        "id": "cZJVJ24nL2mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "id": "pvEp-wiVL4Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Forest Parsing Functions**\n",
        "\n"
      ],
      "metadata": {
        "id": "9NiAXSnTL8Ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load up MP3s"
      ],
      "metadata": {
        "id": "3E21SUu8MGCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mp3_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
        "    res = tfio.audio.AudioIOTensor(filename)\n",
        "    # Convert to tensor and combine channels \n",
        "    tensor = res.to_tensor()\n",
        "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 \n",
        "    # Extract sample rate and cast\n",
        "    sample_rate = res.rate\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # Resample to 16 kHz\n",
        "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ],
      "metadata": {
        "id": "NGuf8u4wMD8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
      ],
      "metadata": {
        "id": "FedgRWXRMLEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wav = load_mp3_16k_mono(mp3)"
      ],
      "metadata": {
        "id": "sFTaA6oWMv-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
      ],
      "metadata": {
        "id": "SUhJv40AM2EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples, index = audio_slices.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "qhSbrIi0M3zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Function to Convert Clips into Windowed Spectrograms"
      ],
      "metadata": {
        "id": "BGkuMPAsM66s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_mp3(sample, index):\n",
        "    sample = sample[0]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, sample],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram"
      ],
      "metadata": {
        "id": "pYpTyVf8M9Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Longer Clips into Windows and Make Predictions"
      ],
      "metadata": {
        "id": "_Te83k5vNCp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
        "audio_slices = audio_slices.map(preprocess_mp3)\n",
        "audio_slices = audio_slices.batch(64)"
      ],
      "metadata": {
        "id": "pJRoMbZMM_c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(audio_slices)\n",
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "id": "USbt9kEwNHUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group Consecutive Detections"
      ],
      "metadata": {
        "id": "mPJrOlR7NOqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby"
      ],
      "metadata": {
        "id": "vUYxROxsNNKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = [key for key, group in groupby(yhat)]\n",
        "calls = tf.math.reduce_sum(yhat).numpy()"
      ],
      "metadata": {
        "id": "5NW7zEVKNT8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calls"
      ],
      "metadata": {
        "id": "K7nrDD4nNVbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Make Predictions**"
      ],
      "metadata": {
        "id": "EwRoGjGQNXwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loop over all recordings and make predictions"
      ],
      "metadata": {
        "id": "cQ-fbSkTNZ8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
        "    FILEPATH = os.path.join('data','Forest Recordings', file)\n",
        "    \n",
        "    wav = load_mp3_16k_mono(FILEPATH)\n",
        "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
        "    audio_slices = audio_slices.map(preprocess_mp3)\n",
        "    audio_slices = audio_slices.batch(64)\n",
        "    \n",
        "    yhat = model.predict(audio_slices)\n",
        "    \n",
        "    results[file] = yhat\n"
      ],
      "metadata": {
        "id": "Y7Vm9nVPNdQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "we6YsbYeNf7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Predictions into Classes"
      ],
      "metadata": {
        "id": "6ynayNtBNiOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds = {}\n",
        "for file, logits in results.items():\n",
        "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
        "class_preds"
      ],
      "metadata": {
        "id": "yHvKNEXiNkIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group Consecutive Detections"
      ],
      "metadata": {
        "id": "GfeSMwSQNpPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "postprocessed = {}\n",
        "for file, scores in class_preds.items():\n",
        "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
        "postprocessed"
      ],
      "metadata": {
        "id": "DmOE4QpwNnVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export Results**"
      ],
      "metadata": {
        "id": "Xhv3k5VeNuc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "Nj1H8ZpUNxDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('results.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f, delimiter=',')\n",
        "    writer.writerow(['recording', 'capuchin_calls'])\n",
        "    for key, value in postprocessed.items():\n",
        "        writer.writerow([key, value])"
      ],
      "metadata": {
        "id": "uUvuuXgTNyHw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}